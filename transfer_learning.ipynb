{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcvOIptdiZR4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import pathlib"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEuCKCoSigaB",
        "outputId": "65ec8157-c78b-4f16-833a-abcbb8a50bca"
      },
      "source": [
        "#Construct imagenet logit-to-class-name dictionary (imagenet_int_to_str)\n",
        "!wget https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\n",
        "\n",
        "imagenet_int_to_str = {}\n",
        "\n",
        "with open('ilsvrc2012_wordnet_lemmas.txt', 'r') as f:\n",
        "  for i in range(1000):\n",
        "    row = f.readline()\n",
        "    row = row.rstrip()\n",
        "    imagenet_int_to_str.update({i: row})"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-29 21:08:31--  https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 142.250.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21675 (21K) [text/plain]\n",
            "Saving to: ‘ilsvrc2012_wordnet_lemmas.txt.1’\n",
            "\n",
            "\r          ilsvrc201   0%[                    ]       0  --.-KB/s               \rilsvrc2012_wordnet_ 100%[===================>]  21.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-29 21:08:31 (111 MB/s) - ‘ilsvrc2012_wordnet_lemmas.txt.1’ saved [21675/21675]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxNW3fARio1b"
      },
      "source": [
        "# Load feature vector extractor into KerasLayer\n",
        "r50x1_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n",
        "feat_vec_layer = hub.KerasLayer(r50x1_url)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oblh_pZJjrWN"
      },
      "source": [
        "def preprocess_image(image):\n",
        "  image = np.array(image)\n",
        "  # reshape into shape [batch_size, height, width, num_channels]\n",
        "  img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  image = tf.image.convert_image_dtype(img_reshaped, tf.float32)  \n",
        "  return image\n",
        "\n",
        "def load_image_from_url(url):\n",
        "  \"\"\"Returns an image with shape [1, height, width, num_channels].\"\"\"\n",
        "  response = requests.get(url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  image = preprocess_image(image)\n",
        "  return image"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nq2qF1Ci0wc"
      },
      "source": [
        "# test feature vector\n",
        "\n",
        "# Load image\n",
        "img_url = \"https://p0.pikrepo.com/preview/853/907/close-up-photo-of-gray-elephant.jpg\"\n",
        "image = load_image_from_url(img_url)\n",
        "\n",
        "# Run model on image\n",
        "logits = feat_vec_layer(image)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsRxPuCFjxOe",
        "outputId": "44044ca0-4f05-4932-8bd4-c4299e3cb944"
      },
      "source": [
        "logits # 2048-dimensional feature vector"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2048), dtype=float32, numpy=\n",
              "array([[0.31866226, 0.        , 8.563895  , ..., 0.79412353, 0.5398085 ,\n",
              "        6.881541  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTG-27noj1h1"
      },
      "source": [
        "class RGB_TL_model(tf.keras.Model):\n",
        "  \"\"\"transfer learning model using feature vector and custom new head\"\"\"\n",
        "\n",
        "  def __init__(self, num_classes, embedding_layer):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_classes = num_classes\n",
        "    self.head = tf.keras.layers.Dense(num_classes, kernel_initializer='zeros')\n",
        "    self.embedding_layer = embedding_layer\n",
        "  \n",
        "  def call(self, images):\n",
        "    img_embedding = self.embedding_layer(images)\n",
        "    pred = self.head(img_embedding)\n",
        "    \n",
        "    return pred"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqQA0ufpk7yL"
      },
      "source": [
        "NUM_CLASSES = 2\n",
        "\n",
        "model = RGB_TL_model(num_classes=NUM_CLASSES, embedding_layer=feat_vec_layer)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvG67wf91wb2"
      },
      "source": [
        "IM_SIZE = (640, 480)\n",
        "\n",
        "model.build(input_shape=(None, 640,480,3))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnI2SycF1c8N",
        "outputId": "de8f0c3f-508e-498d-e1b4-602c3deb21c2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"rgb_tl_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              multiple                  4098      \n",
            "_________________________________________________________________\n",
            "keras_layer_1 (KerasLayer)   multiple                  23500352  \n",
            "=================================================================\n",
            "Total params: 23,504,450\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 23,500,352\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6GZ1TlUlFCg",
        "outputId": "b93628d8-b3a8-4807-b9e3-9d8784830ad6"
      },
      "source": [
        "model(image)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ln4TmyE2VmH"
      },
      "source": [
        "IM_SIZE = (640, 480)\n",
        "rgb_dataset = tf.keras.preprocessing.image_dataset_from_directory(rgb_out_path, labels='inferred', label_mode='categorical', \n",
        "                                                                  image_size=IM_SIZE, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS0g1K632hEo"
      },
      "source": [
        "model.fit(rgb_dataset, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}